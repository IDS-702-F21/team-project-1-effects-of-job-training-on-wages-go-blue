---
output:
  pdf_document: default
  html_document: default
---
# Summary 

In this analysis, we explore the effectiveness of the National Support Work (NSW) Demonstration program on the wages of the disadvantaged male workers. The focus is mainly to compare males who participated in the program versus the ones who did not participate and determine whether the participants are more likely to be employed in 1978.

We also identify demographic factors that are likely to increase the chances earning a non-zero wage for these workers. Exploratory data analysis and stepwise selection are performed to determine the logistic regression model. We observe that people who participated in the program are more likely the to earn a non-zero wage as compared to people who did not participate. Age of the male workers was found to be an interesting variable as its effect on odds of earning a non-zero wage was different for the males who participated as compared to the non-participants.

# Data Pre-processing

We used the re78 variable provided to us in the dataset to create a binary variable re78Bi_F, which indicates whether the person was earning a non-zero wage in 1978 or not.  We use this factor variable as the response variable in our analysis. We ensure that the independent variables have the correct data type before proceeding with the analysis. The variables treat, black, hispan, married and no-degree were converted to factors, while the age and education were used as numeric variables in our model.


# Exploratory Data Analysis

We start our EDA by observing the trend of our preditor variables on our response variable which is re78_F. Given that the treat variable is the main variable of interest, we explore it first. We see that the probability for earning a non zero wage is approximately the same for everyone regardless they took part in the NSW training or not. We also conducted Chi-squared test to test the association between the two variables and given our p-value, we fail to reject the null. The table indicating the conditional probabilities is provided below:

```{r,, results= "asis", echo=FALSE, warning=FALSE, message=FALSE}
library(stargazer)
options(stargazer.comment = FALSE)
library(xtable)
library(ggplot2)
library(rms)
library(arm)
library(e1071)
library(caret)
library(pROC)
library(stargazer)

nsw <- read.csv("/Users/mohammadanas/Desktop/Duke MIDS/Fall 2021/MODELLING AND REPRESENTATION OF DATA/Team Project 1/lalondedata.txt",header=T,
                colClasses=c("factor","factor","numeric","numeric",
                             "factor", "factor", "factor", "factor", 
                             "numeric", "numeric", "numeric"))

nsw$re78Bi <- 0
nsw$re78Bi[nsw$re78 > 0] <- 1
nsw$re78Bi_F <- "Zero W"
nsw$re78Bi_F[nsw$re78Bi == 1] <- "NonZero W"
nsw$re78Bi_F <- factor(nsw$re78Bi_F)

nsw$educ_F <- "1.Elementary"
nsw$educ_F[nsw$educ >= 6 & nsw$educ < 10] <- "2.Middle"
nsw$educ_F[nsw$educ >= 10 & nsw$educ < 13] <- "3.High School"
nsw$educ_F[nsw$educ >= 13] <- "4.After high"
nsw$educ_F <- factor(nsw$educ_F)
treat_re78 <- apply(table(nsw[,c("re78Bi_F","treat")])/sum(table(nsw[,c("re78Bi_F","treat")])),
      2,function(x) x/sum(x)) 
stargazer(treat_re78, type ='latex', title = 'Conditional Probabilities', header = FALSE, digits = 2, no.space = TRUE)

```

We test the association of our response variable with other factor variables as well using the similar procedure. We notice that black people are less likely to earn a non-zero wage as compared to non-black people. The Chi-squared test shows us that the variables Hispanic, married and no-degree have no association with the our response variable. We create box plots to explore the affect of our continuous predictors on our response variable. The box plots indicate that educated people are more likely to earn non zero wages. We also note that younger people are more likely to earn non-zero wages. 

We move on to explore whether the effect of any of our predictors on our response variable varies with other variables. The box plots below indicate that for people who did not participate in the NSW training, younger people are more likely to earn non-zero wages, while the trend seems to be the opposite for the people who took part in the training. 

```{r,, results= "asis", echo=FALSE, warning=FALSE, message=FALSE, fig.height= 3}
library(ggplot2)
ggplot(nsw,aes(x=re78Bi_F, y=age, fill=re78Bi_F)) +
  geom_boxplot() + #coord_flip() +
  scale_fill_brewer(palette="Reds") +
  labs(title="Age vs Wage by Treatment",
       x="Wage?",y="Age") + theme(plot.title = element_text(hjust = 'center')) +
  theme_classic() + theme(legend.position="none") + facet_wrap(~treat)
```


We also observed that for non black people, the training was more effective. Therefore, we include the interaction for black and treatment variable in our model. Based on the results from our EDA, we saw that the interactions affects of age and education, Hispanic and treatment variable and earning in 1974 and treatment variable are worth investigating as well.

# Model Building

We start by fitting a simple model that includes only the main effects except the no-degree variable. We exclude this variable from our model as it is strongly correlated with our education variable. The results of the model seem counter-intuitive as our main variable of interest, the treatment variable is statistically insignificant. We also note that the real earnings of a person in 1974, age_centered and black variables have a significant affect on the odds on earning a non-zero wage in 1978. The residual deviance of our model is 634.95 which suggests that model is a better fit than the null model. Moving on to the model assessment, we make binned plots of the residuals against the fitted values and the continuous predictors. We check for randomness in these plots to ensure that our model satisfies the independence of errors assumption and to investigate whether we need to add transformations for the continuous predictors. Our binned plot for residuals against fitted values looks random except that there are two outliers on the left side of plot. Our binned plots against continuous predictors look random for education and re74, indicating that we do not need any transformations for these two variables. However, for the age_centered variable, we see a polynomial trend that has not been captured by our model. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, results="asis", fig.show='hold', out.width="50%"}
nsw$age_c <- nsw$age - mean(nsw$age)
nsw$re78Bi_F <- factor(nsw$re78Bi,
                       levels=c(0,1),labels=c("Zero","Non-Zero"))
#Model 2 - Main effects (Numeric Education)
base_model <- glm(re78Bi_F ~ educ + black + hispan + treat + re74 + age_c + 
                 married, data = nsw, family = binomial) # FINAL BASE MODEL

#summary(base_model)
# Model 1 - considers all the main effects (excluding No degree)and education as numeric)
# At 95% significance Black, Re74 and Age_c are significant
# AIC = 650.95

#Model Assessment

#save the raw residuals
rawresid1 <- residuals(base_model,"resp")

#binned residual plots - model
binnedplot(x=fitted(base_model),y=rawresid1,xlab="Pred. probabilities",
        col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
#looks good

# For significant coeffs
#binned residual plots - centered Age
binnedplot(x=nsw$age_c,y=rawresid1,xlab="Age centered",
           col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
#no trend 2 points outside

#binned residual plots - Re74
#binnedplot(x=nsw$re74,y=rawresid1,xlab="Re74",
        #   col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
#not as much of a trend 2 points outside

#binned residual plots - Educ
#binnedplot(x=nsw$educ,y=rawresid1,xlab="Educ",
        #   col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")

# Model validation

# #let's do the confusion matrix with .5 threshold
# Conf_mat <- confusionMatrix(as.factor(ifelse(fitted(base_model) >= 0.5, "1","0")),
#                             as.factor(nsw$re78Bi),positive = "1")
# Conf_mat$table
# Conf_mat$overall["Accuracy"];
# Conf_mat$byClass[c("Sensitivity","Specificity")] #True positive rate and True negative rate
# #Maybe we can try to increase that accuracy.
# #Also, the TNR looks low here.
# 
# #look at ROC curve
# roc(nsw$re78Bi_F,fitted(Model_2),plot=T,print.thres="best",legacy.axes=T,
#     print.auc =T,col="red3")
# 
# #first, let's repeat with the marginal percentage in the data
# 
# Conf_mat <- confusionMatrix(as.factor(ifelse(fitted(Model_2) >= 0.784, "1","0")),
#                             as.factor(nsw$re78Bi),positive = "1")
# Conf_mat$table
# Conf_mat$overall["Accuracy"];
# Conf_mat$byClass[c("Sensitivity","Specificity")]

# ~~~~~~~~~~~~~~~~~BASE_LINE IS OUR BASELINE MODEL, WITH BASELINE ACCURACY~~~~~~~~~~~~~~~~~~~~~~
```

To improve our model's fit, we start adding interactions to our model. We adopt a step wise variable selection approach combined with Chi-squared tests to see which variables and interaction affects improve the fit of our model. To do this we create a null model, where we only include the variables of interest; the treat variable, demographic variables (black, hispanic and age_centered) and the interaction of treat variable with all the demographic variables. On the other hand, our full model contains all the variables and interactions in the null model, the interactions that were found to be interesting in the EDA and the married and education variable. We then perform step wise model selection twice, once using AIC as a criteria for variable selection and once using BIC. Both AIC and BIC allow us to keep treat, age_centered, re74 and the interaction between treat and age_centered variables in our model. However, as AIC tends to be more lenient as compared to BIC, it also selects black, hispanic, interaction of treat and hispanic variable and interaction of treat and black variables as well.  The results of the model containing predictor variables using AIC are shown below.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis', fig.}
n <- nrow(nsw)

null_model <- glm(re78Bi_F~ treat + age_c + black + hispan + treat:black + treat:hispan + treat:age_c,data=nsw,family=binomial)

full_model <- glm(re78Bi_F ~ treat*black  + treat*hispan + re74*treat + educ*black + age_c*treat 
                  + age_c*educ + married, data = nsw, family = binomial)

AIC_stepwise <- step(null_model, scope = formula(full_model),direction="both",trace=0)
#summary(AIC_stepwise)
# Model call - re78Bi_F ~ treat + age_c + black + hispan + re74 + treat:hispan + 
#   treat:age_c + treat:re74
library(xtable)
options(xtable.comment = FALSE)
xtable(AIC_stepwise, type ='latex', title = 'Results of Our Model', header = FALSE, digits = 2, no.space = TRUE)
#BIC_stepwise <- step(null_model,scope= formula(full_model),direction="both",
     #trace=0,k = log(n))
#summary(BIC_stepwise)
# Model call - re78Bi_F ~ treat + age_c + re74 + treat:age_c

# ~~~~~~~~ Work in progress ~~~~~~~~~~~~~
# Comparing the AIC and BIC models by an ANOVA test
#anova(BIC_stepwise, AIC_stepwise, test = "Chisq")

# ~~~~~~~~~~~~~~~~~~~~~AIC_Stepwise is our final model~~~~~~~~~~~~~~~~~~~~~~~~~~~
```

To check whether the AIC model fits that data better than the BIC model, we conduct a Chi-squared test and compared the residual deviance of these two models. The p-value of this test turns out to be 0.012, indicating that at least one of the additional variables selected in our AIC model is improving the fit of our model. We see in the results of our AIC model that the variables black and the interaction between treat and re74 variables have low p-values. Therefore, we created a new model which included these two variables and all the variables in our BIC model. We compared this model to the BIC model using a Chi-squared test. The difference was statistically significant and we decided to keep these two variables in our model. To check if the remaining variables in the AIC model (hispanic and its interaction with treat variable) would improve the fit of our model, we conduct another Chi-squared to compare the residual deviance between our new model and the AIC model. Based on the results of this test we chose not to add hispanic and its interaction with the treat variable to our model. 

The results of our model suggest that all the variables are significant except the interaction of treat and re74 variable. We also note that the residual deviance of this model falls to 626.03 proving that this is a better fit as compared to the model that included only the main effects. However, when we look at the binned plot of residuals against our continuous predictors and predicted probabilities, we see that the polynomial trend in the age_centered variables has still not been captured.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
Final_Model <- glm(formula = re78Bi_F ~ treat + age_c  + re74 + black 
                + treat:age_c + treat:re74, family = binomial, 
                   data = nsw)
#summary(Final_Model)

#rawresid4 <- residuals(Final_Model,"resp")

#par(mfcol=c(1,1))

#binnedplot(x=fitted(Final_Model),y=rawresid4,xlab="Pred. probabilities",
           #col.int="red4",ylab="Avg. residuals",main="Binned residual plot_1",col.pts="navy")

# Real Annual Earnings in 1974
#binnedplot(x=nsw$re74,y=rawresid4,xlab="re74 Earnings",
           #col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")

# Centered Age
#binnedplot(x=nsw$age_c,y=rawresid4,xlab="Age centered",
           #col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
```

We observe that the trend of residuals changes twice against the values of our age_centered variable, convincing us to include the squared and cubic degree polynomials of age_centered variable in our model. We also included the interactions of the treat variable with age_squared and age_cubed variables. We run the regression again with the additional variables to check if this improves our model. However, the residual deviance of this model turned out to be 620.32 which is not a significant improvement over our previous model, which is also confirmed by a Chi-squared test. We compared the binned residual plots of these models against the fitted values. These plots are shown below.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis', , fig.show='hold', out.width="50%"}
#Transformations with the age predictor

nsw$age_c_sq <- (nsw$age_c)^2
nsw$age_c_cb <- (nsw$age_c)^3

Final_Model_1_sq <- glm(formula = re78Bi_F ~ treat + age_c  + age_c_sq + re74 + black
                + treat:age_c + treat:age_c_sq + treat:re74, family = binomial, data = nsw)
#summary(Final_Model_1_sq)

Final_Model_1_cb <- glm(formula = re78Bi_F ~ treat + age_c  + age_c_sq + age_c_cb + re74 + black 
                + treat:age_c + treat:age_c_sq + treat:age_c_cb + treat:re74, family = binomial, data = nsw)
#summary(Final_Model_1_cb)
#anova(Final_Model_1_cb, Final_Model, test = "Chisq")
rawresid4 <- residuals(Final_Model,"resp")

par(mfcol=c(1,1))

binnedplot(x=fitted(Final_Model),y=rawresid4,xlab="Pred. probabilities",
           col.int="red4",ylab="Avg. residuals",main="Binned residual plot_1",col.pts="navy")
#rawresid5 <- residuals(Final_Model_1_sq,"resp")
#binnedplot(x=fitted(Final_Model_1_sq),y=rawresid5,xlab="Pred. probabilities",
 #         col.int="red4",ylab="Avg. residuals",main="Binned residual plot_sq",col.pts="navy")

#binnedplot(x=nsw$age_c,y=rawresid5,xlab="Age",
 #         col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
#binnedplot(x=nsw$age_c_sq,y=rawresid5,xlab="Age squared",
 #         col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")

rawresid6 <- residuals(Final_Model_1_cb,"resp")
par(mfcol=c(1,1))
binnedplot(x=fitted(Final_Model_1_cb),y=rawresid6,xlab="Pred. probabilities",
           col.int="red4",ylab="Avg. residuals",main="Binned residual plot_cb",col.pts="navy")

#binnedplot(x=nsw$age_c,y=rawresid6,xlab="Age",
 #          col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
#binnedplot(x=nsw$age_c_sq,y=rawresid6,xlab="Age squared",
 #          col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
#binnedplot(x=nsw$age_c_cb,y=rawresid6,xlab="Age Cubed",
 #          col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")

```

We see that there is not much difference in these plots and the outliers on the left side of the plot are still present. Given that adding the squared and cubic terms of age in our model makes it harder to interpret the standard estimates and does not significantly improve the fit of our model, we decided not to include them in our model. Now that we have investigated the affect of including interactions and transformations to our model, our final model equation is given below.

\begin{equation}
log(\frac{\pi_{i}}{1 - \pi_{i}}) = \beta_{0} \hspace{1mm} + \hspace{1mm} \beta_{1}treat_{i1} \hspace{1mm} +  \hspace{1mm} \beta_{2}age(centered)_{i2} \hspace{1mm} + \hspace{1mm}  \beta_{3}black_{i3} \hspace{1mm} + \hspace{1mm}  \beta_{4}re74_{i4} \hspace{1mm} + \hspace{1mm} \beta_{5}treat*age(centered)_{i5} \hspace{1mm} + \hspace{1mm} \beta_{6}treat*re74_{i6}
\end{equation}

We now move on to test how well our model performs on predicting outcomes. We use our model to predict outcomes on the train data set available to us and then estimate the accuracy of our model's prediction by measuring the area under the ROC curve which is shown below.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis', fig.height=3.5, fig.width=3.5, fig.align='center', results='hide'}
#ROC curve...
roc(nsw$re78Bi,fitted(Final_Model),plot=T,print.thres="best",legacy.axes=T,print.auc =T,col="red3")
```

We then use the confusion matrix to calculate the accuracy, sensitivity and specificity of our model. Classifying the outcomes using the probability threshold of 0.5 allows us to achieve an accuracy of 78% and sensitivity of 98%. However, we see that our model does a poor job at predicting people who did earned a zero wages in 1978 (11% specificity). Therefore, to obtain a balance between specificity and sensitivity, we classify outcomes based on the probability threshold suggested by the ROC curve, which 0.752. Using this threshold, we are able to achieve sensitivity rate of 63% and specificity rate increases to 60%.

The standard estimates of all the coefficients in our model were statistically significant except the interaction between treat and re74 variable. We exponentiate the standard estimates and their confidence intervals to interpret them on the odds scale. Below are the results of our model. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis', , fig.show='hold', out.width="50%"}
#Transformations with the age predictor
Final_Model <- glm(formula = re78Bi_F ~ age_c + re74 + treat  + black 
                + treat:age_c + treat:re74, family = binomial, 
                   data = nsw)


p_value <- xtable(Final_Model)[,-1]
coeffecients <- c(exp(Final_Model$coefficients))
coeffecients_2.5 <- c(exp(confint.default(Final_Model))[,1])
coeffecients_97.5 <- c(exp(confint.default(Final_Model))[,2])

tab1<- cbind(coeffecients_2.5, coeffecients, coeffecients_97.5, p_value)
options(xtable.comment = FALSE)

xtable(tab1, type ='latex', title = 'Results of Our Model', header = FALSE, digits = 2, no.space = TRUE)

```

Despite having interactions, multicollinearity is not present in our model as the variance inflation factor of each of the variables is below 10. A table indicating the VIFs of all the variables in our model is provided below.




```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Checking multicollinearity

library(rms)
vif_table <- xtable(as.table(vif(Final_Model)))
xtable(vif_table)
# All variables well within range

```

# Conclusion


To sum up our analysis, the people who participated in the program are more likely to earn a non-zero wage in 1978 as compared to people who did not participate. Statistically speaking, the odds of earning positive wages after receiving training is 1.89 times the odds of a person who did not receive training for a 27 year old male who was unemployed in 1974. Age was found to an interesting variable in our analysis. For a person who did not receive training, a 1 year increase in age decreases the odds of earning positive wages by 5.5%. However,for people who participated in the training, 1 year increase in age leads to an increase in the odds of earning a non-zero wage by 1.9%. We get this value by multiplying the standard estimates (odds scale) of the age variable and interaction variable between age and treat. Being a non-black person also increases the odds of earning a non-zero wages in 1978. 

# Limitations

Lastly, it is important to point out the limitations in our model.

* Our model assumes that the length of the NSW training remained the same for all participants. However, in reality some participants joined the training program in 1974 while others joined in 1975. 
* There is an uneven distribution in our response variable. The data is highly skewed towards people earning non-zero wages. A potential solution to this problem can be under sampling the data of males earning non-zero wages. 



